from log_config import get_logger
logger = get_logger(__name__)

import openai
from openai import OpenAI
import pandas as pd
import numpy as np
import os
import json
import hashlib
from difflib import get_close_matches

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

COLUNA_ATIVIDADE = "Nome do CNAE"

STOPWORDS = {"para", "com", "sem", "de", "e", "ou", "por", "em", "da", "do", "no", "na", "das", "dos"}

arquivo_excel = "Tabela 14.xlsx"  # ou vari√°vel din√¢mica se estiver usando uploads
sheets_dict = pd.read_excel(arquivo_excel, sheet_name=None)
sheet_names = list(sheets_dict.keys())



# Cache para embeddings
embedding_cache_path = "embedding_cache.json"
if os.path.exists(embedding_cache_path):
    with open(embedding_cache_path, "r") as f:
        EMBEDDING_CACHE = json.load(f)
else:
    EMBEDDING_CACHE = {}

def get_embedding(text):
    hash_key = hashlib.sha256(text.encode()).hexdigest()
    if hash_key in EMBEDDING_CACHE:
        return EMBEDDING_CACHE[hash_key]
    try:
        response = client.embeddings.create(input=[text], model="text-embedding-3-small")
        embedding = response.data[0].embedding
        EMBEDDING_CACHE[hash_key] = embedding
        with open(embedding_cache_path, "w") as f:
            json.dump(EMBEDDING_CACHE, f)
        return embedding
    except Exception as e:
        logger.error(f"Erro ao gerar embedding: {e}")
        return None

def cosine_similarity(v1, v2):
    v1 = np.array(v1)
    v2 = np.array(v2)
    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))

# L√™ todas as abas do arquivo Excel



for nome, df in sheets_dict.items():
    logger.warning(f"[DEBUG] {nome}: colunas = {df.columns.tolist()}")



equivalencias_semanticas = {
    "agroneg√≥cio": ["agropecu√°ria", "agricultura", "pecu√°ria", "produ√ß√£o rural", "cultivo", "planta√ß√£o", "fazenda"],
    "aliment√≠cio": ["alimentos", "ind√∫stria de alimentos", "bebidas", "fabrica√ß√£o de alimentos", "comida", "processamento alimentar"],
    "log√≠stica": ["transporte", "armazenagem", "distribui√ß√£o", "frete", "entrega", "supply chain", "cadeia log√≠stica"],
    "varejo": ["com√©rcio varejista", "lojas", "shopping", "ponto de venda", "pdv", "retail", "com√©rcio"],
    "atacado": ["com√©rcio atacadista", "distribuidor", "distribui√ß√£o em massa", "atacadista"],
    "farmac√™utico": ["rem√©dios", "medicamentos", "farm√°cias", "ind√∫stria farmac√™utica", "sa√∫de", "laborat√≥rio"],
    "hospitalar": ["hospitais", "cl√≠nicas", "sa√∫de", "unidade de sa√∫de", "UPA", "postos de sa√∫de", "pronto socorro"],
    "constru√ß√£o civil": ["obras", "empreiteira", "construtora", "infraestrutura", "engenharia civil", "im√≥veis em constru√ß√£o"],
    "imobili√°rio": ["im√≥veis", "incorporadora", "construtora", "venda de im√≥veis", "loca√ß√£o de im√≥veis"],
    "financeiro": ["finan√ßas", "bancos", "meios de pagamento", "institui√ß√µes financeiras", "cooperativa de cr√©dito"],
    "seguros": ["corretora", "plano de sa√∫de", "seguradora", "seguro de vida", "auto", "patrim√¥nio"],
    "automotivo": ["carros", "ve√≠culos", "oficinas", "autope√ßas", "montadoras", "revendedoras"],
    "educa√ß√£o": ["escolas", "ensino", "universidade", "col√©gio", "faculdade", "institui√ß√µes de ensino"],
    "tecnologia": ["TI", "software", "hardware", "sistemas", "desenvolvimento de software", "startups"],
    "ind√∫stria t√™xtil": ["tecidos", "malharia", "confec√ß√£o", "roupas", "vestu√°rio", "moda"],
    "cal√ßadista": ["sapatos", "cal√ßados", "fabrica√ß√£o de cal√ßados"],
    "cosm√©ticos": ["beleza", "perfumes", "est√©tica", "cuidados pessoais", "produtos de beleza"],
    "minera√ß√£o": ["mineradora", "extra√ß√£o mineral", "bauxita", "ferro", "min√©rio", "carv√£o"],
    "siderurgia": ["a√ßo", "metalurgia", "fundi√ß√µes", "lamina√ß√£o de a√ßo", "ind√∫stria do a√ßo"],
    "qu√≠mico": ["produtos qu√≠micos", "solventes", "resinas", "ind√∫stria qu√≠mica"],
    "pl√°stico": ["ind√∫stria pl√°stica", "embalagens pl√°sticas", "injetoras", "extrusoras"],
    "embalagens": ["packaging", "caixas", "r√≥tulos", "frascos", "embalagens em geral"],
    "papel e celulose": ["papel", "ind√∫stria de papel", "f√°bricas de papel", "papel√£o", "celulose"],
    "editorial": ["gr√°fica", "editoras", "livros", "publica√ß√µes", "revistas", "jornais"],
    "energia": ["usinas", "distribuidoras de energia", "solar", "e√≥lica", "hidrel√©trica", "gera√ß√£o de energia"],
    "telecomunica√ß√µes": ["telefonia", "internet", "provedores", "infraestrutura de redes", "operadoras"],
    "limpeza": ["produtos de limpeza", "higiene", "desinfetantes", "sanitiza√ß√£o"],
    "condom√≠nios": ["s√≠ndico", "gest√£o condominial", "residenciais", "condom√≠nios empresariais"],
    "hotelaria": ["hot√©is", "resorts", "pousadas", "turismo", "hospitalidade"],
    "turismo": ["ag√™ncias", "viagens", "pacotes tur√≠sticos", "guias tur√≠sticos"],
    "transportes": ["fretamento", "rodovi√°rio", "ferrovi√°rio", "mar√≠timo", "log√≠stica", "entregas"],
    "aeron√°utico": ["avi√µes", "manuten√ß√£o de aeronaves", "aeroportos", "aeronaves", "fabricantes de aeronaves"],
    "naval": ["ind√∫stria naval", "embarca√ß√µes", "estaleiros", "transporte mar√≠timo"],
    "mec√¢nico": ["usinagem", "autope√ßas", "componentes mec√¢nicos", "mec√¢nica industrial"],
    "metal√∫rgico": ["fundi√ß√µes", "soldagem", "ind√∫stria de metais", "usinagem"],
    "moveleiro": ["m√≥veis", "marcenaria", "ind√∫stria de m√≥veis", "design de interiores"],
    "frigor√≠fico": ["carnes", "processamento de alimentos", "abatedouros", "resfriados"],
    "bebidas": ["cervejarias", "refrigerantes", "√°gua", "vinhos", "ind√∫stria de bebidas"],
    "meio ambiente": ["res√≠duos", "coleta seletiva", "tratamento de √°gua", "energia renov√°vel", "reciclagem"],
    "seguran√ßa": ["monitoramento", "portaria", "seguran√ßa patrimonial", "vigil√¢ncia", "alarmistas"],
    "RH": ["recrutamento", "recursos humanos", "terceiriza√ß√£o de m√£o de obra", "gest√£o de talentos"],
    "jur√≠dico": ["advocacia", "escrit√≥rio de advocacia", "consultoria jur√≠dica"],
    "cont√°bil": ["contabilidade", "escrit√≥rios cont√°beis", "consultoria tribut√°ria"],
    "esportes": ["academias", "fitness", "esporte coletivo", "esporte individual", "clubes"],
    "entretenimento": ["eventos", "shows", "cinema", "m√∫sica", "streaming"],
    "e-commerce": ["lojas online", "marketplaces", "plataformas de venda", "com√©rcio eletr√¥nico"],
    "pet": ["produtos para animais", "veterin√°rios", "cl√≠nicas pet", "alimentos para pets"],
    "eventos": ["cerimonial", "buffets", "organiza√ß√£o de eventos", "festas", "congressos"],
    "limpeza urbana": ["coleta de lixo", "varri√ß√£o", "gest√£o de res√≠duos urbanos", "servi√ßos p√∫blicos"],
    "servi√ßos gerais": ["terceiriza√ß√£o", "multisservi√ßos", "facilities", "m√£o de obra auxiliar"]
}


equivalencias_semanticas_canais = {
    
    # Segmentos de canais desejados
    "tecnologia": ["ti", "software", "hardware", "sistemas", "desenvolvimento de software", "startups"],
    "gest√£o": ["administra√ß√£o", "gerenciamento", "gest√£o empresarial", "consultoria em gest√£o"],
    "inform√°tica": ["tecnologia da informa√ß√£o", "infraestrutura de ti", "servi√ßos de inform√°tica", "manuten√ß√£o de computadores"],
    "internet": ["web", "rede", "provedor de internet", "plataformas digitais", "aplica√ß√µes online", "servi√ßos online"],
    "consultoria": ["assessoria", "consultoria empresarial", "consultoria estrat√©gica", "servi√ßos especializados"]
}


def expandir_termos_por_equivalencia(lista_termos: list[str], base: dict) -> set:
    termos_expandidos = set()
    for termo in lista_termos:
        termo = termo.lower()
        similares = base.get(termo, [])
        termos_expandidos.update([termo] + similares)
    return termos_expandidos


def extrair_dados_segmentos_cliente_e_canais(segmentos_cliente: list[str], top_n: int = 30):
    
    #   Extrai informa√ß√µes das cidades com base nos segmentos informados pelo cliente (Empresa) 
    #   e nos segmentos fixos definidos para canais de vendas.

    #etorna:
    #   DataFrame com as colunas:
    #   - Municipio
    #   - Empresas_Segmento (segmentos da empresa)
    #   - Empresas_Perfil_Canal (segmentos fixos de canais)

    dfs_processados = []  # ‚úÖ Adicione aqui antes do for

    excel_file = pd.ExcelFile(arquivo_excel)
    sheet_names = excel_file.sheet_names
    
    logger.warning(f"[DEBUG] Abas lidas do Excel: {sheet_names}")

    termos_cliente = set()

    for termo in segmentos_cliente:
        termos_cliente.update(normalizar_segmentos_inteligente(termo, descricoes_cnae, embeddings_cnae))

    segmentos_canais_input = list(equivalencias_semanticas_canais.keys())

    termos_canais = set()
    
    for termo in segmentos_canais_input:
        normalizados = normalizar_segmentos_inteligente(termo, descricoes_cnae, embeddings_cnae)   
        termos_canais.update(normalizados)
    
    resultados = {}

    for nome_aba in sheet_names:

        # Tenta encontrar a linha onde est√° o cabe√ßalho correto

        aba = sheets_dict[nome_aba]

        linha_cabecalho = aba[aba.apply(lambda x: x.astype(str).str.contains("Municipio", case=False)).any(axis=1)].index.min()

        if pd.isna(linha_cabecalho):
            logger.warning(f"[ERRO] Cabe√ßalho n√£o encontrado na aba {nome_aba}")
            continue

        df = pd.read_excel(arquivo_excel, sheet_name=nome_aba, skiprows=linha_cabecalho)

        # Verifica se as colunas necess√°rias est√£o presentes

        colunas_esperadas = {"Municipio", "Nome do CNAE", "N√∫mero de unidades locais"}
        
        if not colunas_esperadas.issubset(df.columns):
            logger.warning(f"[ERRO] Cabe√ßalho n√£o encontrado na aba {nome_aba}")
            continue

        df = df[["Municipio", "Nome do CNAE", "N√∫mero de unidades locais"]]
        
        df = df.rename(columns={"Nome do CNAE": COLUNA_ATIVIDADE, "N√∫mero de unidades locais": "Unidades_Locais"})

        df = df[df["Municipio"].notna()]
        df = df[~df["Municipio"].astype(str).str.contains("Munic|Tabela|Total", na=False)]
        df = df[~df["Unidades_Locais"].astype(str).isin(["-", "nan"])]
        df["Unidades_Locais"] = pd.to_numeric(df["Unidades_Locais"], errors="coerce")
        df = df[df["Unidades_Locais"].notna()]

        df[COLUNA_ATIVIDADE] = df[COLUNA_ATIVIDADE].astype(str).str.lower()

        df["Origem"] = "Excel"
        dfs_processados.append(df)


        if not {"Municipio", "Nome do CNAE", "N√∫mero de unidades locais"}.issubset(df.columns):
            logger.warning(f"[ERRO] Colunas esperadas n√£o encontradas na aba {nome_aba}")
            continue

        df = df[["Municipio", "Nome do CNAE", "N√∫mero de unidades locais"]]
        df = df.rename(columns={"Nome do CNAE": COLUNA_ATIVIDADE, "N√∫mero de unidades locais": "Unidades_Locais"})

        df = df[df["Municipio"].notna()]
        df = df[~df["Municipio"].astype(str).str.contains("Munic|Tabela|Total", na=False)]
        df = df[~df["Unidades_Locais"].astype(str).isin(["-", "nan"])]
        df["Unidades_Locais"] = pd.to_numeric(df["Unidades_Locais"], errors="coerce")
        df = df[df["Unidades_Locais"].notna()]

        df[COLUNA_ATIVIDADE] = df[COLUNA_ATIVIDADE].astype(str).str.lower()

        contagem_segmento = contar_empresas_por_segmento(df, termos_cliente)
        contagem_canal = contar_empresas_por_segmento(df, termos_canais)

        dfs_processados.append(df)


        if not dfs_processados:
            logger.error("‚ùå Nenhum DataFrame v√°lido foi processado. Verifique os dados.")
            return pd.DataFrame()



    if not dfs_processados:
        logger.warning("Nenhuma aba com dados v√°lidos foi processada.")
        return pd.DataFrame(columns=["Municipio", "Empresas_Segmento", "Empresas_Perfil_Canal"])

    
    df_total = pd.concat(dfs_processados, ignore_index=True)
    df_total["Municipio"] = df_total["Municipio"].astype(str).str.strip().str.title()

    contagem_segmento = contar_empresas_por_segmento(df_total, termos_cliente)
    contagem_canal = contar_empresas_por_segmento(df_total, termos_canais)
    
    
    for cidade in set(contagem_segmento.keys()).union(contagem_canal.keys()):
        if cidade not in resultados:
            resultados[cidade] = {"Empresas_Segmento": 0, "Empresas_Perfil_Canal": 0}

        resultados[cidade]["Empresas_Segmento"] += contagem_segmento.get(cidade, 0)
        resultados[cidade]["Empresas_Perfil_Canal"] += contagem_canal.get(cidade, 0)

    df_final = pd.DataFrame([
        {"Municipio": k, "Empresas_Segmento": v["Empresas_Segmento"], "Empresas_Perfil_Canal": v["Empresas_Perfil_Canal"]}
        for k, v in resultados.items()

        ])

    logger.warning(f"[DEBUG] Linhas encontradas: {len(df_final)}")
    logger.warning(f"[DEBUG] Amostra do DataFrame:\n{df_final.head()}")

    return df_final.sort_values(by="Empresas_Segmento", ascending=False).head(top_n).reset_index(drop=True)


def buscar_similares_embedding(termo: str, descricoes: list[str], threshold: float = 0.35, top_n: int = 3) -> list[str]:
    """
    Retorna as descri√ß√µes mais semelhantes ao termo fornecido com base em embeddings,
    fuzzy matching e fallback para match parcial por string.
    """
    try:
        termo_emb = get_embedding(termo)
        if not termo_emb:
            logger.warning(f"Embedding nulo para termo: {termo}")
            return []

        # Calcula similaridade com todas as descri√ß√µes
        pontuacoes = []
        for descricao in descricoes:
            desc_emb = get_embedding(descricao)
            if desc_emb:
                score = cosine_similarity(termo_emb, desc_emb)
                pontuacoes.append((descricao, score))

        # Filtra por threshold
        filtradas = [desc for desc, score in pontuacoes if score >= threshold]
        if filtradas:
            return sorted(filtradas, key=lambda x: -dict(pontuacoes)[x])[:top_n]

        # Fallback: fuzzy matching
        fuzzy = get_close_matches(termo, descricoes, n=top_n, cutoff=0.5)
        if fuzzy:
            logger.info(f"Fuzzy matching usado para termo '{termo}'")
            return fuzzy

        # √öltimo recurso: match parcial
        parciais = [desc for desc in descricoes if termo.lower() in desc.lower()]
        if parciais:
            return parciais[:top_n]

        return []

    except Exception as e:
        logger.error(f"Erro em buscar_similares_embedding: {e}")
        return []


def normalizar_segmentos_inteligente(termo_usuario: str, descricoes_cnae: list[str], embeddings_cnae: list[list[float]], usar_openai_fallback: bool = False) -> list[str]:
    """
    Normaliza um termo informado com base nas descri√ß√µes CNAE e retorna os termos mais semelhantes.
    Usa: equival√™ncia sem√¢ntica ‚Üí embedding ‚Üí fuzzy ‚Üí fallback
    """
    termo = termo_usuario.strip().lower()

    # 1. Verifica se existe correspond√™ncia direta no dicion√°rio de equival√™ncias

    for chave, lista in equivalencias_semanticas.items():
        if termo == chave or termo in lista:
            return list(set([chave] + lista))

    # 2. Similaridade por embedding
    try:
        emb_termo = get_embedding(termo)
        if not emb_termo:
            logger.warning(f"Embedding n√£o encontrado para termo: {termo}")
        else:
            similaridades = [cosine_similarity(emb_termo, emb) for emb in embeddings_cnae]
            top_indices = np.argsort(similaridades)[::-1]
            top_descricoes = [descricoes_cnae[i] for i in top_indices if similaridades[i] > 0.35][:5]
            if top_descricoes:
                return top_descricoes
    except Exception as e:
        logger.warning(f"Erro em embedding do termo '{termo}': {e}")

    # 3. Fuzzy matching
    fuzzy = get_close_matches(termo, descricoes_cnae, n=5, cutoff=0.4)
    if fuzzy:
        return fuzzy

    # 4. Fallback com OpenAI (opcional)
    if usar_openai_fallback:
        try:
            prompt = f"""Voc√™ √© um classificador inteligente. A seguir, est√° um termo de atividade empresarial: '{termo_usuario}'.
Retorne uma descri√ß√£o de atividade CNAE brasileira mais pr√≥xima poss√≠vel.
"""
            resposta = client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.4
            )
            texto = resposta.choices[0].message.content.strip()
            return [texto]
        except Exception as e:
            logger.error(f"Erro no fallback OpenAI para termo '{termo}': {e}")

    # 5. Fallback final
    return [termo_usuario]


def buscar_cidades_na_openai(segmentos: list[str], cidades_existentes: list[str], faltantes: int):
    prompt = f"""
Considere segmentos de atua√ß√£o: {", ".join(segmentos)}.
Com base nisso, sugira {faltantes} cidades brasileiras com grande potencial de mercado para empresas desses segmentos.
Evite repetir as cidades j√° listadas: {", ".join(cidades_existentes)}.
Para cada cidade, retorne: Nome da Cidade, N√∫mero de empresas no segmento, N√∫mero de empresas com perfil para ser canal.
Retorne os dados em uma tabela CSV com colunas: Municipio, Empresas_Segmento, Empresas_Perfil_Canal
    """
    try:
        resposta = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "Voc√™ √© um analista de intelig√™ncia de mercado brasileiro."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.4,
            max_tokens=1200
        )
        import io
        tabela_csv = resposta.choices[0].message.content.strip()

        try:
            df = pd.read_csv(io.StringIO(tabela_csv))
            return df  # ‚úÖ Retorna apenas se o CSV foi lido com sucesso
        except Exception as e:
            logger.error(f"Erro ao ler CSV gerado pela OpenAI: {e}\nConte√∫do recebido:\n{tabela_csv}")
            return pd.DataFrame()  # S√≥ retorna vazio se deu erro
        
    except Exception as e:
        logger.error(f"Erro ao buscar cidades com OpenAI: {e}")
        return pd.DataFrame()


def filtrar_municipios_por_segmentos_multiplos(segmentos_textuais: str, top_n: int = 30) -> pd.DataFrame:
    
    """
    Fun√ß√£o intermedi√°ria que transforma texto solto em lista de segmentos e
    executa a busca por munic√≠pios com base no novo motor inteligente.
    """

    segmentos_lista = [
        seg.strip().lower()
        for seg in segmentos_textuais.replace(",", " ").split()
            if seg.strip().lower() not in STOPWORDS and len(seg.strip()) > 2
    ]

    logger.warning(f"[DEBUG] Segmentos processados para busca: {segmentos_lista}")  # ‚úÖ AGORA SIM


    if not segmentos_lista:
        logger.warning("Nenhum segmento v√°lido informado.")
        return pd.DataFrame(columns=["Municipio", "Empresas_Segmento", "Empresas_Perfil_Canal"])

    # Aponta diretamente para o motor novo e unificado
    df_resultado = extrair_dados_segmentos_cliente_e_canais(segmentos_lista, top_n=top_n)

    if df_resultado.empty:
        logger.warning("Nenhum munic√≠pio encontrado para os segmentos informados.")
        return df_resultado

    logger.warning(f"[DEBUG FINAL] Total cidades Excel: {len(df_resultado)}")


def gerar_tabela_html(dataframe: pd.DataFrame) -> str:
    if dataframe.empty:
        return """
        <div class='paragrafo'>
            <h3 style='color:#5e17eb;'>üìç Nenhum munic√≠pio encontrado para os segmentos informados.</h3>
            <p>Revise os termos utilizados ou tente um conjunto de segmentos mais amplo.</p>
        </div>
        """

    linhas = ""
    for _, row in dataframe.iterrows():
        linhas += (
            f"<tr>"
            f"<td>{row['Municipio']}</td>"
            f"<td>{int(row['Empresas_Segmento'])}</td>"
            f"<td>{int(row['Empresas_Perfil_Canal'])}</td>"
            f"</tr>"
        )

    return f"""
    <div class='paragrafo'>
        <h3 style='color:#5e17eb;'>üìç Top 30 Munic√≠pios com Maior Potencial por Segmentos</h3>
        <table border='0' width='100%' style='font-size:15px; line-height:1.5; border-collapse:collapse; margin-top:15px;'>
            <thead style='background:#f0f0f0;'>
                <tr>
                    <th align='left'>Munic√≠pio</th>
                    <th align='left'>Empresas no Segmento da Empresa</th>
                    <th align='left'>Empresas com Perfil de Canal</th>
                </tr>
            </thead>
            <tbody>
                {linhas}
            </tbody>
        </table>
    </div>
    """

# Export√°veis globais
try:
    descricoes_cnae = set()
    for nome_aba in sheet_names:
        df_sheet = sheets_dict[nome_aba]

        if "Nome do CNAE" in df_sheet.columns:
            descricoes = df_sheet["Nome do CNAE"].dropna().unique().tolist()
            descricoes_cnae.update(descricoes)

    descricoes_cnae = list(descricoes_cnae)
    embeddings_cnae = [get_embedding(desc) for desc in descricoes_cnae]
except Exception as e:
    descricoes_cnae = []
    embeddings_cnae = []
    logger.warning(f"Erro ao preparar descri√ß√µes e embeddings globais: {e}")

import re

def cnae_bate_com_qualquer_termo(cnae: str, termos: set[str]) -> bool:
    tokens = set(re.findall(r"\w+", cnae.lower()))
    return any(t in tokens for t in termos)

def contar_empresas_por_segmento(df: pd.DataFrame, termos: set[str]) -> dict[str, int]:
    contagem = {}
    for _, row in df.iterrows():
        cidade = row["Municipio"]
        atividade = str(row[COLUNA_ATIVIDADE]).lower()
        unidades = row["Unidades_Locais"]
        if cidade not in contagem:
            contagem[cidade] = 0
        if cnae_bate_com_qualquer_termo(atividade, termos):
            contagem[cidade] += unidades
    return contagem

